{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Préliminaire: préparation des données sous forme d'arbres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe noyau s’est bloqué lors de l’exécution du code dans une cellule active ou une cellule précédente. \n",
      "\u001b[1;31mVeuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. \n",
      "\u001b[1;31mCliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import numpy as np\n",
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_tree():\n",
    "    # Initialisation du graphe\n",
    "    g = dgl.graph(([], []))\n",
    "    labels = ['TD']  # Étiquette pour le nœud racine\n",
    "    g.add_nodes(1)\n",
    "    node_features = [np.random.rand()]  # Indice aléatoire pour la racine\n",
    "\n",
    "    # Niveau 1: enfants 'PC' de 'TD'\n",
    "    num_children_td = np.random.randint(2, 6)  # entre 2 et 5 enfants\n",
    "    pc_nodes = list(range(g.num_nodes(), g.num_nodes() + num_children_td))\n",
    "    g.add_nodes(num_children_td)\n",
    "    node_features.extend(np.random.rand(num_children_td).tolist())\n",
    "    labels.extend(['PC'] * num_children_td)\n",
    "    g.add_edges([0] * num_children_td, pc_nodes)\n",
    "\n",
    "    # Niveau 2: enfants 'GOP' de chaque 'PC'\n",
    "    gop_nodes = []\n",
    "    for pc_node in pc_nodes:\n",
    "        num_children_pc = np.random.randint(1, 4)  # entre 1 et 3 enfants\n",
    "        children = list(range(g.num_nodes(), g.num_nodes() + num_children_pc))\n",
    "        g.add_nodes(num_children_pc)\n",
    "        node_features.extend(np.random.rand(num_children_pc).tolist())\n",
    "        labels.extend(['GOP'] * num_children_pc)\n",
    "        g.add_edges([pc_node] * num_children_pc, children)\n",
    "        gop_nodes.extend(children)\n",
    "\n",
    "    # Niveau 3: enfants 'Deals' de chaque 'GOP'\n",
    "    deal_nodes = []\n",
    "    for gop_node in gop_nodes:\n",
    "        num_children_gop = np.random.randint(4, 11)  # entre 4 et 10 enfants\n",
    "        children = list(range(g.num_nodes(), g.num_nodes() + num_children_gop))\n",
    "        g.add_nodes(num_children_gop)\n",
    "        node_features.extend(np.random.rand(num_children_gop).tolist())\n",
    "        labels.extend(['Deals'] * num_children_gop)\n",
    "        g.add_edges([gop_node] * num_children_gop, children)\n",
    "        deal_nodes.extend(children)\n",
    "\n",
    "    # Niveau 4: enfants 'Market Datas' de chaque 'Deal', chacun ayant exactement 5 enfants\n",
    "    for deal_node in deal_nodes:\n",
    "        num_children_deal = 5\n",
    "        children = list(range(g.num_nodes(), g.num_nodes() + num_children_deal))\n",
    "        g.add_nodes(num_children_deal)\n",
    "        node_features.extend(np.random.rand(num_children_deal).tolist())\n",
    "        labels.extend(['Market Datas'] * num_children_deal)\n",
    "        g.add_edges([deal_node] * num_children_deal, children)\n",
    "\n",
    "    # Assignation des indices aléatoires comme caractéristiques des nœuds\n",
    "    g.ndata['feature'] = torch.tensor(node_features, dtype=torch.float32)\n",
    "    return g, labels\n",
    "\n",
    "def plot_tree(g, labels):\n",
    "    plt.figure(figsize=(20, 30))\n",
    "    nx_g = g.to_networkx().to_undirected()\n",
    "    pos = nx.spring_layout(nx_g, scale=20)\n",
    "\n",
    "    color_map = {\n",
    "        'TD': 'gold',\n",
    "        'PC': 'limegreen',\n",
    "        'GOP': 'cyan',\n",
    "        'Deals': 'magenta',\n",
    "        'Market Datas': 'blue'\n",
    "    }\n",
    "    node_color = [color_map[label] for label in labels]\n",
    "    node_labels = {i: f\"{label}\\n{g.ndata['feature'][i].item():.2f}\" for i, label in enumerate(labels)}\n",
    "\n",
    "    nx.draw(nx_g, pos, node_color=node_color, with_labels=True, labels=node_labels, node_size=500, font_size=12, font_color='darkred')\n",
    "\n",
    "    from matplotlib.lines import Line2D\n",
    "    legend_elements = [Line2D([0], [0], marker='o', color='w', label=key,\n",
    "                              markerfacecolor=val, markersize=15) for key, val in color_map.items()]\n",
    "    plt.legend(handles=legend_elements, title=\"Node Types\")\n",
    "    plt.show()\n",
    "\n",
    "# Génération du graphe et labels\n",
    "tree, labels = generate_tree()\n",
    "\n",
    "# Visualisation du graphe\n",
    "plot_tree(tree, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 100\n",
      "Number of 0s: 30\n",
      "Number of 1s: 70\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dgl\n",
    "\n",
    "def generate_data(num_samples=100, zero_ratio=0.3):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # Détermination du nombre de labels à 0 et 1\n",
    "    num_zeros = int(num_samples * zero_ratio)\n",
    "    num_ones = num_samples - num_zeros\n",
    "    labels = [0] * num_zeros + [1] * num_ones\n",
    "    np.random.shuffle(labels)  # Mélange des labels pour randomisation\n",
    "    \n",
    "    for label in labels:\n",
    "        # Génération du graphe\n",
    "        g, node_labels = generate_tree()\n",
    "        X.append((g,node_labels))\n",
    "        y.append(label)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Appel de la fonction pour générer les données\n",
    "X, y = generate_data()\n",
    "\n",
    "# Vérification rapide des proportions et de la taille de la liste\n",
    "print(\"Total samples:\", len(X))\n",
    "print(\"Number of 0s:\", y.count(0))\n",
    "print(\"Number of 1s:\", y.count(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Définir le Modèle de Réseau de Neurones pour Graphes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn import GraphConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        x = F.relu(self.conv1(g, features))\n",
    "        x = self.conv2(g, x)\n",
    "        x = dgl.mean_nodes(g, 'h')  # Moyenne des embeddings des nœuds pour obtenir une représentation globale du graphe\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Préparation des Données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate(samples):\n",
    "    graphs, labels = map(list, zip(*samples))\n",
    "    batched_graph = dgl.batch([g for g, _ in graphs])\n",
    "    features = torch.cat([g.ndata['feature'].float().unsqueeze(1) for g, _ in graphs], 0)\n",
    "    labels = torch.tensor(labels)\n",
    "    return batched_graph, features, labels\n",
    "\n",
    "# Transformer les données en paires (graphe, label)\n",
    "graph_label_pairs = [(X[i][0], y[i]) for i in range(len(y))]\n",
    "data_loader = DataLoader(graph_label_pairs, batch_size=10, shuffle=True, collate_fn=collate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Entraînement du Modèle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "DGLError",
     "evalue": "Invalid key \"0\". Must be one of the edge types.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m             optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[35], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m():\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):  \u001b[38;5;66;03m# On fait un entraînement simple pour tester\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatched_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatched_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\decroux paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\decroux paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\decroux paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[34], line 5\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(samples)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollate\u001b[39m(samples):\n\u001b[0;32m      4\u001b[0m     graphs, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39msamples))\n\u001b[1;32m----> 5\u001b[0m     batched_graph \u001b[38;5;241m=\u001b[39m dgl\u001b[38;5;241m.\u001b[39mbatch(\u001b[43m[\u001b[49m\u001b[43mg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraphs\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      6\u001b[0m     features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([g\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m g, _ \u001b[38;5;129;01min\u001b[39;00m graphs], \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      7\u001b[0m     labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(labels)\n",
      "Cell \u001b[1;32mIn[34], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollate\u001b[39m(samples):\n\u001b[0;32m      4\u001b[0m     graphs, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39msamples))\n\u001b[1;32m----> 5\u001b[0m     batched_graph \u001b[38;5;241m=\u001b[39m dgl\u001b[38;5;241m.\u001b[39mbatch([g \u001b[38;5;28;01mfor\u001b[39;00m g, _ \u001b[38;5;129;01min\u001b[39;00m graphs])\n\u001b[0;32m      6\u001b[0m     features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([g\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m g, _ \u001b[38;5;129;01min\u001b[39;00m graphs], \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      7\u001b[0m     labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(labels)\n",
      "File \u001b[1;32mc:\\Users\\decroux paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dgl\\heterograph.py:2411\u001b[0m, in \u001b[0;36mDGLGraph.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2408\u001b[0m etypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_etypes(key)\n\u001b[0;32m   2410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(etypes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2411\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DGLError(\n\u001b[0;32m   2412\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid key \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. Must be one of the edge types.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2413\u001b[0m             orig_key\n\u001b[0;32m   2414\u001b[0m         )\n\u001b[0;32m   2415\u001b[0m     )\n\u001b[0;32m   2417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(etypes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2418\u001b[0m     \u001b[38;5;66;03m# no ambiguity: return the unitgraph itself\u001b[39;00m\n\u001b[0;32m   2419\u001b[0m     srctype, etype, dsttype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_canonical_etypes[etypes[\u001b[38;5;241m0\u001b[39m]]\n",
      "\u001b[1;31mDGLError\u001b[0m: Invalid key \"0\". Must be one of the edge types."
     ]
    }
   ],
   "source": [
    "# Configuration de l'apprentissage\n",
    "model = GCN(in_feats=1, h_feats=16, num_classes=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    for epoch in range(10):  # On fait un entraînement simple pour tester\n",
    "        for batched_graph, features, labels in data_loader:\n",
    "            pred = model(batched_graph, features)\n",
    "            loss = criterion(pred, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
