Dans un premier temps, mon objectif était de mettre en place une classification en séries temporelles basée sur des données agrégées au niveau des portefeuilles, en utilisant des features descriptives de ces portefeuilles. L'idée était d'examiner les séries temporelles pour identifier les moments où les valeurs subissent des sauts significatifs, en m'appuyant sur une labellisation issue des incidents historiques rapportés par les analystes. Cependant, la labellisation des incidents s'est avérée extrêmement approximative. Les incidents peuvent être déclarés à différents niveaux—portefeuille ou groupe de portefeuilles—mais ils reflètent souvent des problèmes survenus en réalité au niveau des deals individuels.

Un consensus s'est dégagé pour affirmer qu'un modèle qui se contenterait de flagger les groupes de portefeuilles ne serait pas d'une grande utilité, car il n'affinerait que très peu le travail de l'analyste. Ce qui est crucial, c'est de descendre dans le détail, au niveau du portefeuille ou du deal, les deux niveaux les plus bas de la structure analytique. Malheureusement, la réalité des données disponibles et la nature incomplète de la labellisation font qu'une approche en séries temporelles devient impraticable. En effet, les incidents déclarés au niveau des groupes de portefeuilles n'identifient pas spécifiquement les portefeuilles touchés, ce qui rompt la continuité temporelle nécessaire à une telle analyse.

De plus, même si des données plus qualitatives existent, l'accès à celles-ci ne m'a été possible que très tardivement, bien après le début du projet. J'ai donc dû me résoudre à réaliser une classification sans tenir compte de l'aspect historique des données, en me basant uniquement sur des données agrégées au niveau des portefeuilles. Cette situation, où l'on travaille avec des données limitées et non optimales, correspond parfaitement à l'adage "garbage in, garbage out". En d'autres termes, les résultats risquent de ne pas être pertinents si les données d'entrée ne sont pas de qualité.

Malgré cela, cette approche de classification restait la plus simple à mettre en place dans un premier temps, en dépit de mes réserves sur son efficacité. C'était un passage obligé pour comprendre les limites des données disponibles et pour identifier les axes d'amélioration possibles en vue d'une solution plus robuste.